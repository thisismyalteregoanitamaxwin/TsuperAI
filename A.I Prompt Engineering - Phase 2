import streamlit as st
import os
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.llms import HuggingFaceHub
from langchain_community.vectorstores import FAISS

st.set_page_config(page_title="TsuperAI (Hugging Face)", page_icon="ðŸ‡µðŸ‡­")
st.title("TsuperAI: Your Commuter Assistant")

st.sidebar.title("Configuration")
hf_token = st.sidebar.text_input("Enter your Hugging Face API Token", type="password")

if hf_token:
    os.environ["HUGGINGFACEHUB_API_TOKEN"] = hf_token
    st.sidebar.success("API Token set!")
else:
    st.sidebar.warning("Please enter your Hugging Face API Token to continue.")

uploaded_file = st.file_uploader("Upload a PDF file with Metro Manila transport data", type="pdf")

if uploaded_file and hf_token:
    try:
        temp_path = "temp_transport_data.pdf"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getvalue())
        
        loader = PyPDFLoader(temp_path)
        documents = loader.load_and_split()

        embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

        db = FAISS.from_documents(documents, embeddings)
        retriever = db.as_retriever(search_kwargs={"k": 3})

        llm = HuggingFaceHub(
            repo_id="mistralai/Mistral-7B-Instruct-v0.2",
            task="text-generation",
            model_kwargs={"temperature": 0.1, "max_new_tokens": 300}
        )

        template = """
Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say you don't know.
Use three sentences maximum and keep the answer concise and helpful.

Context: {context}

Question: {question}

Helpful Answer:
"""
        prompt = PromptTemplate.from_template(template)

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

        st.header("Ask TsuperAI for Directions")
        query = st.text_input("e.g., How do I get from AMA Cubao to SM North?")

        if query:
            with st.spinner("TsuperAI is thinking..."):
                answer = rag_chain.invoke(query)
                st.subheader("TsuperAI's Answer:")
                st.write(answer)

                with st.expander("See Sources"):
                    source_documents = retriever.invoke(query)
                    for doc in source_documents:
                        st.write(doc.page_content)

    except Exception as e:
        st.error(f"An error occurred: {e}")

    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

elif uploaded_file and not hf_token:
    st.warning("Please provide your Hugging Face token in the sidebar before uploading a file.")
